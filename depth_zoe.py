import torch
import cv2
import numpy as np
from transformers import ZoeDepthForDepthEstimation, ZoeDepthImageProcessor
import os

# åŠ è½½ ZoeDepth æ¨¡å‹ï¼ˆåŸºç¡€ç‰ˆï¼‰
model = ZoeDepthForDepthEstimation.from_pretrained("Intel/zoedepth-nyu-kitti")
processor = ZoeDepthImageProcessor.from_pretrained("Intel/zoedepth-nyu-kitti")


def enhance_depth_map(depth_map):
    """
    å¢å¼ºæ·±åº¦å›¾çš„æ¸…æ™°åº¦å’Œå¯¹æ¯”åº¦
    """
    # 1. é«˜æ–¯æ»¤æ³¢å»å™ª
    depth_smooth = cv2.GaussianBlur(depth_map, (3, 3), 0.5)

    # 2. è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    depth_enhanced = clahe.apply((depth_smooth * 255).astype(np.uint8))

    # 3. è¾¹ç¼˜ä¿æŒæ»¤æ³¢ï¼ˆåŒè¾¹æ»¤æ³¢ï¼‰
    depth_filtered = cv2.bilateralFilter(depth_enhanced, 9, 75, 75)

    return depth_filtered / 255.0


def apply_gamma_correction(depth_map, gamma=0.7):
    """
    åº”ç”¨ä¼½é©¬æ ¡æ­£æå‡æš—éƒ¨ç»†èŠ‚
    """
    return np.power(depth_map, gamma)


def normalize_depth_advanced(depth_map, percentile_clip=2):
    """
    é«˜çº§æ·±åº¦å›¾å½’ä¸€åŒ–ï¼Œä½¿ç”¨ç™¾åˆ†ä½æ•°è£å‰ªé¿å…æå€¼å½±å“
    """
    # è®¡ç®—ç™¾åˆ†ä½æ•°
    low_percentile = np.percentile(depth_map, percentile_clip)
    high_percentile = np.percentile(depth_map, 100 - percentile_clip)

    # è£å‰ªæå€¼
    depth_clipped = np.clip(depth_map, low_percentile, high_percentile)

    # å½’ä¸€åŒ–åˆ° 0-1
    depth_normalized = (depth_clipped - low_percentile) / (
        high_percentile - low_percentile
    )

    return depth_normalized


def generate_depth_map(
    image_path, output_path="depth.png", enhance_quality=True, save_16bit=False
):
    """
    ç”Ÿæˆé«˜è´¨é‡æ·±åº¦å›¾

    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºæ·±åº¦å›¾è·¯å¾„
        enhance_quality: æ˜¯å¦å¯ç”¨è´¨é‡å¢å¼º
        save_16bit: æ˜¯å¦ä¿å­˜16ä½æ·±åº¦å›¾ï¼ˆæ›´é«˜ç²¾åº¦ï¼‰
    """
    # è¯»å–å›¾åƒï¼ˆBGR -> RGBï¼‰
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")

    original_height, original_width = image.shape[:2]
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # é¢„å¤„ç†
    inputs = processor(images=image_rgb, return_tensors="pt")

    # æ¨ç†
    print("æ­£åœ¨ç”Ÿæˆæ·±åº¦å›¾...")
    with torch.no_grad():
        outputs = model(**inputs)
        predicted_depth = outputs.predicted_depth

    # é«˜è´¨é‡æ’å€¼åˆ°åŸå›¾å¤§å°
    prediction = torch.nn.functional.interpolate(
        predicted_depth.unsqueeze(1),
        size=(original_height, original_width),
        mode="bicubic",
        align_corners=False,
        antialias=True,  # æŠ—é”¯é½¿
    ).squeeze()

    depth_map = prediction.cpu().numpy()

    if enhance_quality:
        print("æ­£åœ¨å¢å¼ºæ·±åº¦å›¾è´¨é‡...")
        # é«˜çº§å½’ä¸€åŒ–
        depth_map = normalize_depth_advanced(depth_map)

        # ä¼½é©¬æ ¡æ­£
        depth_map = apply_gamma_correction(depth_map)

        # è´¨é‡å¢å¼º
        depth_map = enhance_depth_map(depth_map)
    else:
        # åŸºç¡€å½’ä¸€åŒ–
        depth_min = depth_map.min()
        depth_max = depth_map.max()
        depth_map = (depth_map - depth_min) / (depth_max - depth_min)

    # ä¿å­˜æ·±åº¦å›¾
    if save_16bit:
        # ä¿å­˜16ä½æ·±åº¦å›¾ä»¥è·å¾—æ›´é«˜ç²¾åº¦
        depth_16bit = (depth_map * 65535).astype(np.uint16)
        base_name = os.path.splitext(output_path)[0]
        output_16bit = f"{base_name}_16bit.png"
        cv2.imwrite(output_16bit, depth_16bit)
        print(f"âœ… 16ä½æ·±åº¦å›¾å·²ä¿å­˜: {output_16bit}")

    # ä¿å­˜8ä½æ·±åº¦å›¾
    depth_8bit = (depth_map * 255).astype(np.uint8)
    cv2.imwrite(output_path, depth_8bit)
    print(f"âœ… æ·±åº¦å›¾å·²ä¿å­˜: {output_path}")

    # ç”Ÿæˆä¼ªå½©è‰²æ·±åº¦å›¾ç”¨äºå¯è§†åŒ–
    colormap_path = os.path.splitext(output_path)[0] + "_colormap.png"
    depth_colormap = cv2.applyColorMap(depth_8bit, cv2.COLORMAP_PLASMA)
    cv2.imwrite(colormap_path, depth_colormap)
    print(f"âœ… å½©è‰²æ·±åº¦å›¾å·²ä¿å­˜: {colormap_path}")

    return depth_map


if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šå¯¹ä¸€å¼  test.jpg ç”Ÿæˆæ·±åº¦å›¾
    print("=== æ·±åº¦å›¾ç”Ÿæˆæµ‹è¯• ===")

    # ç”Ÿæˆæ ‡å‡†è´¨é‡æ·±åº¦å›¾
    print("\n1. ç”Ÿæˆæ ‡å‡†è´¨é‡æ·±åº¦å›¾...")
    generate_depth_map("test.jpg", "depth_standard.png", enhance_quality=False)

    # ç”Ÿæˆé«˜è´¨é‡æ·±åº¦å›¾
    print("\n2. ç”Ÿæˆé«˜è´¨é‡æ·±åº¦å›¾...")
    generate_depth_map(
        "test.jpg", "depth_enhanced.png", enhance_quality=True, save_16bit=True
    )

    print("\nâœ… æ‰€æœ‰æ·±åº¦å›¾ç”Ÿæˆå®Œæˆï¼")
    print("ğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š")
    print("   - depth_standard.png (æ ‡å‡†è´¨é‡)")
    print("   - depth_enhanced.png (å¢å¼ºè´¨é‡)")
    print("   - depth_enhanced_16bit.png (16ä½é«˜ç²¾åº¦)")
    print("   - depth_enhanced_colormap.png (å½©è‰²å¯è§†åŒ–)")
